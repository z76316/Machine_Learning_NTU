{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate Gaussian Distribution\n",
    "\n",
    "https://en.wikipedia.org/wiki/Multivariate_normal_distribution \n",
    "\n",
    "https://www.youtube.com/watch?v=JjB58InuTqM&index=6&list=LLyG2f9f44zZhZr8cLPOa4UQ&t=1s\n",
    "\n",
    "Note:\n",
    "\n",
    "https://photos.app.goo.gl/Dp8RB1ugEcy5FEEM8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/chia-yuanchang/My_Project/Machine_Learning_NTU/2_predict_income_by_logistic_regression_and_generative_model/dataset/Y_train',\n",
       " '/Users/chia-yuanchang/My_Project/Machine_Learning_NTU/2_predict_income_by_logistic_regression_and_generative_model/dataset/test.csv',\n",
       " '/Users/chia-yuanchang/My_Project/Machine_Learning_NTU/2_predict_income_by_logistic_regression_and_generative_model/dataset/X_train',\n",
       " '/Users/chia-yuanchang/My_Project/Machine_Learning_NTU/2_predict_income_by_logistic_regression_and_generative_model/dataset/train.csv',\n",
       " '/Users/chia-yuanchang/My_Project/Machine_Learning_NTU/2_predict_income_by_logistic_regression_and_generative_model/dataset/X_test',\n",
       " '/Users/chia-yuanchang/My_Project/Machine_Learning_NTU/2_predict_income_by_logistic_regression_and_generative_model/dataset/sample_submission.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_list = glob(os.path.join(os.getcwd(), 'dataset', '*'))\n",
    "path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_Y_train = path_list[0]\n",
    "df_Y_train = pd.read_csv(path_Y_train)\n",
    "# df_Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_X_train = path_list[2]\n",
    "df_X_train = pd.read_csv(path_X_train)\n",
    "# df_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(df_X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_X_test = path_list[4]\n",
    "df_X_test = pd.read_csv(path_X_test)\n",
    "# df_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = path_list[3]\n",
    "df_train = pd.read_csv(path_train)\n",
    "# df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = path_list[1]\n",
    "df_test = pd.read_csv(path_test)\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df_array):\n",
    "    mean = df_array.mean(axis=0)\n",
    "    std = df_array.std(axis=0)\n",
    "    \n",
    "    # To prevent from divide by inf: if std = 0, replace it with 1\n",
    "    std[std == 0] = 1\n",
    "    \n",
    "    df_array_normalized = (df_array - mean) / std\n",
    "    return df_array_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32561, 1), (32561, 106), (16281, 106))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = df_Y_train.values\n",
    "x_train = df_X_train.values\n",
    "x_test = df_X_test.values\n",
    "y_train.shape, x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561,) (32561, 106) (16281, 106)\n",
      "0.0 0.030670557354391753 -0.9941292592084697\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.astype('float')\n",
    "x_train = x_train.astype('float')\n",
    "x_test = x_test.astype('float')\n",
    "\n",
    "y_train = y_train.reshape(-1)\n",
    "\n",
    "x_train = normalize(x_train)\n",
    "x_test = normalize(x_test)\n",
    "\n",
    "print(y_train.shape, x_train.shape, x_test.shape)\n",
    "print(y_train[0], x_train[0,0], x_test[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32561, 106), (32561,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shuffle(arr1, arr2):\n",
    "    id_list = np.arange(len(arr1))\n",
    "    np.random.shuffle(id_list)\n",
    "    \n",
    "    arr1_random = arr1[id_list]\n",
    "    arr2_random = arr2[id_list]\n",
    "    \n",
    "    return arr1_random, arr2_random\n",
    "\n",
    "x_train, y_train = shuffle(x_train, y_train)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train split to (train, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29304, 106), (29304,), (3257, 106), (3257,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split (train, val)\n",
    "split_percent = 0.1\n",
    "num_sample = len(y_train)\n",
    "num_sample_train = int(num_sample * (1 - split_percent))\n",
    "x_train_split = x_train[:num_sample_train]\n",
    "y_train_split = y_train[:num_sample_train]\n",
    "x_val_split = x_train[num_sample_train:]\n",
    "y_val_split = y_train[num_sample_train:]\n",
    "x_train_split.shape, y_train_split.shape, x_val_split.shape, y_val_split.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training data split two groups\n",
    "\n",
    "y = 1, group 1\n",
    "\n",
    "y = 0, group 2 !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7023, 106), (7023,), (22281, 106), (22281,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_group_1 = []\n",
    "y_group_1 = []\n",
    "x_group_2 = []\n",
    "y_group_2 = []\n",
    "\n",
    "for i in range(len(y_train_split)):\n",
    "    if y_train_split[i] == 1:\n",
    "        x_group_1.append(x_train_split[i])\n",
    "        y_group_1.append(y_train_split[i])\n",
    "    else:\n",
    "        x_group_2.append(x_train_split[i])\n",
    "        y_group_2.append(y_train_split[i])\n",
    "        \n",
    "x_group_1 = np.array(x_group_1)\n",
    "y_group_1 = np.array(y_group_1)\n",
    "x_group_2 = np.array(x_group_2)\n",
    "y_group_2 = np.array(y_group_2)\n",
    "\n",
    "x_group_1.shape, y_group_1.shape, x_group_2.shape, y_group_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate mu and sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4181739643467947 -0.13025452921487762\n",
      "(106,) (106,)\n"
     ]
    }
   ],
   "source": [
    "mu1 = np.mean(x_group_1, axis=0)\n",
    "mu2 = np.mean(x_group_2, axis=0)\n",
    "\n",
    "print(mu1[0], mu2[0])\n",
    "print(mu1.shape, mu2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7023, 106) (22281, 106)\n",
      "-0.11595461046477588 0.323920892992727\n",
      "-0.5341285748115706 0.45417542220760465\n"
     ]
    }
   ],
   "source": [
    "x_group_1_norm = x_group_1 - mu1\n",
    "x_group_2_norm = x_group_2 - mu2\n",
    "\n",
    "print(x_group_1_norm.shape, x_group_2_norm.shape)\n",
    "print(x_group_1[0,0], x_group_2[0,0])\n",
    "print(x_group_1_norm[0,0], x_group_2_norm[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7023, 22281)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1 = len(x_group_1_norm)\n",
    "n2 = len(x_group_2_norm)\n",
    "\n",
    "n1,n2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 106)\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "x_train_shape = x_train.shape\n",
    "dim = x_train.shape[1]\n",
    "\n",
    "print(x_train_shape)\n",
    "print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-355.5226572180194\n",
      "-355.5226572180194\n"
     ]
    }
   ],
   "source": [
    "# numpy do the matrix transpose automatically\n",
    "print(x_group_1_norm[:,0] @ x_group_1_norm[:,1])\n",
    "print(x_group_1_norm[:,0] @ x_group_1_norm[:,1].transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106, 106) (106, 106)\n"
     ]
    }
   ],
   "source": [
    "sigma1 = np.zeros(shape=[dim,dim])\n",
    "sigma2 = np.zeros(shape=[dim,dim])\n",
    "\n",
    "for i in range(dim):\n",
    "    for j in range(i, dim):\n",
    "        \n",
    "        # group 1\n",
    "        xi = x_group_1_norm[:,i]\n",
    "        xj = x_group_1_norm[:,j]\n",
    "        sigma1[i,j] = (xi @ xj) / n1\n",
    "        sigma1[j,i] = sigma1[i,j]\n",
    "        \n",
    "        # group 2\n",
    "        xi = x_group_2_norm[:,i]\n",
    "        xj = x_group_2_norm[:,j]\n",
    "        sigma2[i,j] = (xi @ xj) / n2\n",
    "        sigma2[j,i] = sigma2[i,j]\n",
    "        \n",
    "print(sigma1.shape, sigma2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge two group's sigma by weight\n",
    "sigma = (n1 / (n1+n2)) * sigma1 + (n2 / (n1+n2)) * sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106, 106)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_inverse = np.linalg.inv(sigma)\n",
    "sigma_inverse.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate w and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = (mu1 - mu2) @ sigma_inverse\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.165555638284293"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = (\n",
    "    - 0.5 * mu1.transpose() @ sigma_inverse @ mu1\n",
    "    - 0.5 * mu2.transpose() @ sigma_inverse @ mu2\n",
    "    + np.log(n1/n2)\n",
    ")\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3257,),\n",
       " array([ 0.26439698, -1.42809348]),\n",
       " array([2.42995262, 0.73746216]),\n",
       " -2.165555638284293)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_val_predict = x_val_split @ w + b\n",
    "# (3257,) = (3257, 106) @ (106,) + (1,)\n",
    "\n",
    "z_val_predict.shape, z_val_predict[:2], (x_val_split @ w)[:2], b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3257,), array([0.56571686, 0.19339592, 0.33341071, 0.00299755, 0.0175906 ]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1 / (1.0 + np.exp(-z))\n",
    "    return np.clip(res, 1e-8, 1-(1e-8))\n",
    "\n",
    "y_val_predict = sigmoid(z_val_predict)\n",
    "y_val_predict.shape, y_val_predict[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8342032545287074"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_predict_category = np.round(y_val_predict)\n",
    "compare = (y_val_predict_category == y_val_split)\n",
    "accuracy = np.sum(compare) / len(y_val_split)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3450664073147981"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_real_0 = y_val_split\n",
    "y_real_1 = 1 - y_val_split\n",
    "y_predict_0 = y_val_predict\n",
    "y_predict_1 = 1 - y_val_predict\n",
    "cross_entropy = - y_real_0 * np.log(y_predict_0) - y_real_1 * np.log(y_predict_1)\n",
    "mean_cross_entropy = np.mean(cross_entropy)\n",
    "mean_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
